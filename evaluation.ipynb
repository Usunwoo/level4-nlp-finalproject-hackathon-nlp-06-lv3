{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result 평가 스크립트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.simplefilter(action=\"ignore\", category=Warning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "GENERATED_SUMMARY_CSV = \"evaluation/data/generated_summary.csv\"\n",
    "GENERATED_CATEGORY_CSV = \"evaluation/data/generated_category.csv\"\n",
    "GENERATED_REPORT_CSV = \"evaluation/data/generated_report.csv\"\n",
    "\n",
    "REFERNECE_CSV = \"evaluation/data/reference.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import 및 환경 주입\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from agents.classification.classification_type import ClassificationType\n",
    "from evaluation.classification.dataframe_manager import DataFrameManager\n",
    "from evaluation.evaluation_summary import evaluate_summary\n",
    "from evaluation.gpt_eval import calculate_g_eval\n",
    "from evaluation.result_printer import print_evaluation_results\n",
    "from utils.configuration import Config\n",
    "\n",
    "load_dotenv()\n",
    "Config.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference Load\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(reference_df): 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>body</th>\n",
       "      <th>subject</th>\n",
       "      <th>category</th>\n",
       "      <th>action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194e90265a3c53fe</td>\n",
       "      <td>*지속가능원이 추천하는 2025-1 지속가능 교과목 25선!*\\n\\nESG? 지속가...</td>\n",
       "      <td>[지속가능원] 지속가능원이 추천하는 2025-1 지속가능 교과목 25선!</td>\n",
       "      <td>other</td>\n",
       "      <td>read only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194e343333e5ff27</td>\n",
       "      <td>\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n</td>\n",
       "      <td>ICT명품인재양성사업단 뉴스레터 겨울호를 보내 드립니다.</td>\n",
       "      <td>academic</td>\n",
       "      <td>read only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194e34039181a3c0</td>\n",
       "      <td>안녕하세요,\\n\\n\\n2024년 업적평가를 위해 실적 업데이트 요청을 드립니다. 이...</td>\n",
       "      <td>2024년 업적평가를 위한 연구실적 업데이트 요청의 건 (~2월 7일)</td>\n",
       "      <td>academic</td>\n",
       "      <td>action needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194e334940f6bad0</td>\n",
       "      <td>안녕하세요\\n친환경 디지털 정보과학 교육연구단 함이열입니다.\\n\\nBK21 대학원혁...</td>\n",
       "      <td>[BK] 2025년 2월 7일(금) BK21 대학원혁신사업 영어논문작성법 워크숍 안...</td>\n",
       "      <td>academic</td>\n",
       "      <td>action needed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194e325d62686180</td>\n",
       "      <td>Hi there,\\n\\nWe charged $5.20 to your credit c...</td>\n",
       "      <td>Your OpenAI API account has been funded</td>\n",
       "      <td>other</td>\n",
       "      <td>read only</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                               body  \\\n",
       "0  194e90265a3c53fe  *지속가능원이 추천하는 2025-1 지속가능 교과목 25선!*\\n\\nESG? 지속가...   \n",
       "1  194e343333e5ff27                         \\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n   \n",
       "2  194e34039181a3c0  안녕하세요,\\n\\n\\n2024년 업적평가를 위해 실적 업데이트 요청을 드립니다. 이...   \n",
       "3  194e334940f6bad0  안녕하세요\\n친환경 디지털 정보과학 교육연구단 함이열입니다.\\n\\nBK21 대학원혁...   \n",
       "4  194e325d62686180  Hi there,\\n\\nWe charged $5.20 to your credit c...   \n",
       "\n",
       "                                             subject  category         action  \n",
       "0           [지속가능원] 지속가능원이 추천하는 2025-1 지속가능 교과목 25선!     other      read only  \n",
       "1                    ICT명품인재양성사업단 뉴스레터 겨울호를 보내 드립니다.  academic      read only  \n",
       "2            2024년 업적평가를 위한 연구실적 업데이트 요청의 건 (~2월 7일)  academic  action needed  \n",
       "3  [BK] 2025년 2월 7일(금) BK21 대학원혁신사업 영어논문작성법 워크숍 안...  academic  action needed  \n",
       "4            Your OpenAI API account has been funded     other      read only  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reference_df = pd.read_csv(REFERNECE_CSV)\n",
    "print(\"len(reference_df):\", len(reference_df))\n",
    "reference_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary 평가\n",
    "\n",
    "1. 요약전 원문(고정)\n",
    "2. REFERENCE(고정)\n",
    "3. 생성 요약문\n",
    "\n",
    "Return\n",
    "ROUGE, BERT SCORE, G-EVAL(with summary)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_summary_df = pd.read_csv(GENERATED_SUMMARY_CSV)\n",
    "print(\"len(generated_summary_df):\", len(generated_summary_df))\n",
    "generated_summary_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_texts = reference_df[\"body\"].tolist()\n",
    "report_texts = generated_summary_df[\"summary\"].tolist()\n",
    "reference_texts = reference_df[\"subject\"].tolist()\n",
    "\n",
    "\n",
    "summary_results = evaluate_summary(source_texts, report_texts, reference_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_evaluation_results(summary_results, eval_type=\"summary\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 분류 평가\n",
    "\n",
    "1. 라벨 Ground truth(고정)\n",
    "2. 여러번 결과(N번) 가지고 있는 리스트\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(generated_category_df): 48\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>categories</th>\n",
       "      <th>actions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>194eaa45baa51ec0</td>\n",
       "      <td>['academic', 'academic', 'academic']</td>\n",
       "      <td>['read only', 'read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>194eaa3c5169e920</td>\n",
       "      <td>['academic', 'academic', 'academic']</td>\n",
       "      <td>['read only', 'read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>194e90265a3c53fe</td>\n",
       "      <td>['other', 'other', 'other']</td>\n",
       "      <td>['read only', 'read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>194e343333e5ff27</td>\n",
       "      <td>['other', 'other', 'other']</td>\n",
       "      <td>['read only', 'read only', 'read only']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>194e34039181a3c0</td>\n",
       "      <td>['administration', 'administration', 'administ...</td>\n",
       "      <td>['action needed', 'action needed', 'action nee...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                         categories  \\\n",
       "0  194eaa45baa51ec0               ['academic', 'academic', 'academic']   \n",
       "1  194eaa3c5169e920               ['academic', 'academic', 'academic']   \n",
       "2  194e90265a3c53fe                        ['other', 'other', 'other']   \n",
       "3  194e343333e5ff27                        ['other', 'other', 'other']   \n",
       "4  194e34039181a3c0  ['administration', 'administration', 'administ...   \n",
       "\n",
       "                                             actions  \n",
       "0            ['read only', 'read only', 'read only']  \n",
       "1            ['read only', 'read only', 'read only']  \n",
       "2            ['read only', 'read only', 'read only']  \n",
       "3            ['read only', 'read only', 'read only']  \n",
       "4  ['action needed', 'action needed', 'action nee...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_category_df = pd.read_csv(GENERATED_CATEGORY_CSV)\n",
    "print(\"len(generated_category_df):\", len(generated_category_df))\n",
    "generated_category_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion Matrix 저장 완료: evaluation/classification/figure/academic_confusion_matrix.png\n",
      "✅ Confusion Matrix 저장 완료: evaluation/classification/figure/administration_confusion_matrix.png\n",
      "✅ Confusion Matrix 저장 완료: evaluation/classification/figure/other_confusion_matrix.png\n",
      "\n",
      "Correctness\n",
      "🎯 전체 정확도: 0.7500\n",
      "🎯 academic 정확도: 0.8125\n",
      "🎯 administration 정확도: 0.8542\n",
      "🎯 other 정확도: 0.8333\n",
      "\n",
      "Consistency\n",
      "📊 Ground Truth 별 요약된 평가 메트릭\n",
      "     Ground Truth   Entropy  Diversity Index  Chi-Square p-value  Accuracy  \\\n",
      "0        academic  0.758937         0.071429                   1  0.714286   \n",
      "1  administration  0.758937         0.071429                   1  0.714286   \n",
      "2           other  0.639032         0.050000                   1  0.800000   \n",
      "\n",
      "   Cramer's V  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "2         0.0  \n",
      "\n",
      "=== Overall Multiclass Confusion Matrix ===\n",
      "Labels: ['academic', 'administration', 'other']\n",
      "[[30  3  9]\n",
      " [ 9 30  3]\n",
      " [ 6  6 48]]\n",
      "===========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "category_df_manager = DataFrameManager(Config.config[\"classification\"][\"inference\"], ClassificationType.CATEGORY)\n",
    "for index, row in generated_category_df.iterrows():\n",
    "    category_df_manager.update_eval_df(\n",
    "        row[\"id\"], ast.literal_eval(row[\"categories\"]), reference_df.loc[index, \"category\"]\n",
    "    )\n",
    "\n",
    "category_df_manager.print_df()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Confusion Matrix 저장 완료: evaluation/classification/figure/action needed_confusion_matrix.png\n",
      "✅ Confusion Matrix 저장 완료: evaluation/classification/figure/read only_confusion_matrix.png\n",
      "\n",
      "Correctness\n",
      "🎯 전체 정확도: 0.7292\n",
      "🎯 action needed 정확도: 0.7292\n",
      "🎯 read only 정확도: 0.7292\n",
      "\n",
      "Consistency\n",
      "📊 Ground Truth 별 요약된 평가 메트릭\n",
      "    Ground Truth   Entropy  Diversity Index  Chi-Square p-value  Accuracy  \\\n",
      "0  action needed  0.545595         0.039216                   1  0.764706   \n",
      "1      read only  0.602440         0.021505                   1  0.709677   \n",
      "\n",
      "   Cramer's V  \n",
      "0         0.0  \n",
      "1         0.0  \n",
      "\n",
      "=== Overall Multiclass Confusion Matrix ===\n",
      "Labels: ['action needed', 'read only']\n",
      "[[39 12]\n",
      " [27 66]]\n",
      "===========================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "action_df_manager = DataFrameManager(Config.config[\"classification\"][\"inference\"], ClassificationType.ACTION)\n",
    "for index, row in generated_category_df.iterrows():\n",
    "    action_df_manager.update_eval_df(row[\"id\"], ast.literal_eval(row[\"actions\"]), reference_df.loc[index, \"action\"])\n",
    "\n",
    "action_df_manager.print_df()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 최종 report 평가\n",
    "\n",
    "1. 요약전 원문(메일 요약문 concat)\n",
    "2. 생성 요약문\n",
    "\n",
    "Return\n",
    "G-EVAL(with final)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generated_report_df = pd.read_csv(GENERATED_REPORT_CSV)\n",
    "print(\"len(generated_report_df):\", len(generated_report_df))\n",
    "generated_report_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "results[\"g-eval\"] = calculate_g_eval(\n",
    "    source_texts=generated_report_df[\"source\"].tolist(),\n",
    "    generated_texts=generated_report_df[\"report\"].tolist(),\n",
    "    eval_type=\"report\",\n",
    "    model_name=Config.config[\"summary\"][\"g_eval\"][\"openai_model\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_evaluation_results(results, eval_type=\"report\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
