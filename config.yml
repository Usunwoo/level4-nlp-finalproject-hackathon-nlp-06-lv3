gmail:
  start_date: # gmail에서 불러올 시작 날짜 (값이 없는 경우 2025/01/10)
  end_date: # gmail에서 불러올 끝 날짜 (값이 없는 경우 오늘 날짜)
  max_mails: 5 # gmail에서 불러올 메일 최대 개수 TODO: 10으로 원상복구

evaluation: # 평가 설정
  summary_eval: false # Summary 평가 수행 여부
  classification_eval: false # Classification 평가 수행 여부
  report_eval: false # Final Report 평가 수행 여부

seed: 42
temperature:
  summary: 0
  classification: 0.7

self_reflection:
  type: self-refine # self-refine | reflexion 변경 가능
  max_iteration: 5 # TODO: 3으로 원상복구
  reflexion:
    threshold_type: "average"
    threshold: 4.5

common_prompts: &common_prompts
  consistency: "prompt/template/g_eval/con_{type}.txt"
  coherence: "prompt/template/g_eval/coh_{type}.txt"
  fluency: "prompt/template/g_eval/flu_{type}.txt"
  relevance: "prompt/template/g_eval/rel_{type}.txt"
  readability: "prompt/template/g_eval/rdb_{type}.txt"
  clearance: "prompt/template/g_eval/clr_{type}.txt"
  practicality: "prompt/template/g_eval/prc_{type}.txt"

summary: # Summary 평가 관련 설정
  metrics:
    - rouge
    - bert
    - g-eval

  bert_model: "distilbert-base-uncased"

  g_eval:
    openai_model: "gpt-4" # summary는 gpt-4가 아니면 정확한 답변 생성이 어려움
    additional: False # "readability", "clearance", "practicality"를 G-Eval에 적용할 여부
    prompts:
      <<: *common_prompts
      type: "summary"

# Report 평가 관련 설정
report:
  metrics:
    - g-eval

  g_eval:
    openai_model: "gpt-4o" # report는 gpt-4o로도 가능
    additional: False # "readability", "clearance", "practicality"를 G-Eval에 적용할 여부
    prompts:
      <<: *common_prompts
      type: "report"

classification:
  do_manual_filter: False
  inference: 1 # TODO: 5로 원상 복구, Consistency 평가 용 반복 추론 횟수 설정

embedding:
  model_name: "bge-m3" # 혹은 "upstage"
  similarity_metric: "cosine-similarity" # 혹은 "dot-product"
  similarity_threshold: 0.8
  save_results: true

token_tracking: true
